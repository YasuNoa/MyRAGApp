# 2025-11-30 開発レポート: Pythonバックエンド移行とAI機能強化

本日は、RAG（検索拡張生成）の中核となるバックエンド処理を、Node.jsから **Python (FastAPI)** へと完全移行し、さらに検索精度と対応フォーマットを大幅に強化しました。

## 1. Pythonバックエンドへの完全移行
### 何をしたか
*   これまで Next.js (Node.js) 内で行っていた「PDF解析」「ベクトル化」「検索」「回答生成」の処理を、全て新設した Python サーバー (`backend/main.py`) に移設しました。
*   Next.js は「フロントエンド」と「認証」に専念し、AI処理は Python に任せる **マイクロサービス構成** になりました。

### なぜしたか (Intent)
*   **AIエコシステムの活用**: AI・機械学習のライブラリは Python が圧倒的に充実しています（LangChain, LlamaIndex, PyTorchなど）。これらを活用するためです。
*   **処理性能と拡張性**: 重い処理を分離することで、アプリ全体の安定性を高め、将来的な機能追加（画像認識や音声認識など）を容易にするためです。

---

## 2. 検索精度の劇的向上 (Re-ranking)
### 何をしたか
*   **Cross-Encoder (`sentence-transformers`)** を導入しました。
*   Pinecone で検索した「候補（Top 10）」に対して、AIが再度「質問と答えの関連度」を厳密に採点し直し、並び替える処理を追加しました。

### 技術的ポイント (Educational)
*   **Bi-Encoder (Pinecone)**: 高速だが、文脈の細かいニュアンスを捉えるのが苦手。
*   **Cross-Encoder (今回導入)**: 計算は重いが、2つの文を突き合わせて「本当に合ってる？」を確認するため、精度が非常に高い。
*   **Hybrid Search**: まず Pinecone で絞り込み、最後に Cross-Encoder で精査する「いいとこ取り」の構成にしました。

---

## 3. OCR (光学文字認識) の実装
### 何をしたか
*   **Tesseract OCR** エンジンを Docker コンテナにインストールしました。
*   PDF からテキストが抽出できなかった場合（スキャンデータなど）、自動的に OCR エンジンを起動して画像から文字を読み取る **フォールバック機能** を実装しました。

### なぜしたか
*   「紙をスキャンしたPDF」や「画像化された資料」も検索対象にするためです。これにより、取り込める知識の幅が大きく広がりました。

---

## 4. チャンク分割の高度化 (LangChain)
### 何をしたか
*   単純な文字数分割ではなく、**LangChain の `RecursiveCharacterTextSplitter`** を導入しました。
*   「。」「、」「改行」などの区切り文字を優先して分割することで、文章の意味が途中で切れてしまう問題を防ぎました。

---

## 5. 最新モデルへのアップグレード
### 何をしたか
*   回答生成モデルを **`gemini-2.0-flash`** に更新しました。
*   **特徴**: 最新世代のモデルで、非常に高速かつ高性能でありながら、コストパフォーマンス（Flash）に優れています。

---

## 今後の展望
*   この強力なバックエンドを基盤に、LINE Bot との連携や、さらなるマルチモーダル対応（画像入力など）を進めていく準備が整いました。
